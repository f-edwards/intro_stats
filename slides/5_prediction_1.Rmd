---
title: "Measurement and visualization, 2"
author: "Frank Edwards"
date: "9/17/2019"
output: binb::metropolis
---

```{r setup, include=FALSE}
rm(list=ls())
library(tidyverse)
library(qss)
library(MASS)
select<-dplyr::select
set.seed(1)
data(afghan)
data(afghan.village)

options(xtable.comment = FALSE)
theme_set(theme_bw())
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
knitr::opts_chunk$set(warning=FALSE, message=FALSE, tidy = TRUE, size = "small")
```

## Announcements

- Christiane's office hours are now Tuesday 10-2
- My office hours are now Friday 10-2
- Homework is now due by 10AM on Wednesdays
- Homework this week: no problem set, but read (or re-read) Wickham Chapter 1-13 and Arnold 1-4. 


# Prediction

## Why predict?

- To descriptively learn about the future (weather, elections, economic changes)
- To validate theories or arguments:
  - Valid causal inference requires successful prediction of counterfactual claims 
  - e.g. if X were different, what value of Y would we observe?

## For loops

- Loops repeat the same set of operations a specified number of times
- Very useful when we need to apply a complex batch of code over a set of rows/columns/data.frames

## General anatomy of a for loop

```{r}
for(i in 1:3){ ### counter, counter range, open loop
  print(i+2) ### expression to evaluate
} ### close the loop
```

## General procedure for writing a loop

1. Think through the procedure
2. Pre-allocate a vector/data.frame for output with correct dimensions for output
3. Run
4. Reshape output to integrate with other objects

## General procedure for writing a loop

*Goal:* Calculate products of 2 for consecutive integers between 1 and 5

```{r}
### create index vector
digits<-seq(from=1,to=5, by=1)
### allocate output vector of needed length
output<-rep(NA, length(digits))
for(i in 1:length(digits)){
  output[i]<-digits[i]*2 # store in output at position i
}
## view!
output
```

## Getting fancy: Nested loops and conditionals
- We can loop within loops!
- We can use if{} and else{} within loops
- Calculate $x =(2x)!$ for $x \in [1,5]$

```{r size = "tiny"}
### create index vector
digits<-seq(from=1,to=5, by=1)
### allocate output vector of needed length
factorial<-rep(NA, length(digits))
for(i in 1:length(digits)){
  start_pt<-digits[i]*2 # factorial start point
  fact_out<-start_pt
  for(k in (start_pt-1):1){
    fact_out<-fact_out * k
  }
  factorial[i]<-fact_out
}
## view!
factorial
```

## Whoa - what is this doing?
*Add an iteration counter and output to check progress*

```{r size = "tiny", echo = FALSE}
for(i in 1:length(digits)){
  start_pt<-digits[i]*2 # factorial start point
  fact_out<-start_pt
  for(k in (start_pt-1):1){
    fact_out<-fact_out * k
    print(paste("i=", i, ", k =", k, 
                ", start_p=", start_pt,
                ", fact_out=", fact_out))
  }
  factorial[i]<-fact_out
}
```

## Data for today: polling and the 2016 election

```{r}
polls<-read_csv("./data/polls2016.csv")
## if not in the .RMD slide file
# polls<-read_csv("./slides/data/polls2016.csv")
head(polls)
polls<-polls %>% 
  filter(population=="Likely Voters") %>% 
  select(state, Clinton, Trump, days_to_election, electoral_votes)
```

## Storing output of a loop

*Goal:* make a table with the mean, median, and SD for both candidates

```{r}
## initiate a storage object with correct dimensions
descriptives_out<-data.frame("Candidate" = rep(NA,2),
                             "Mean" = rep(NA,2),
                             "Median" = rep(NA,2),
                             "SD" = rep(NA,2))
```

## Setting up our loop

```{r size = "scriptsize"}
## Create index vector for select()
columns<-c("Clinton", "Trump")

for(i in 1:length(columns)){ ## use vector length for counter range
  temp<-polls %>% 
    pull(columns[i])
  descriptives_out$Candidate[i]<-columns[i]
  descriptives_out$Mean[i]<-mean(temp)
  descriptives_out$Median[i]<-median(temp)
  descriptives_out$SD[i]<-sd(temp)
}
```

## Checking the output

```{r}
descriptives_out
```

## Working through and debugging the loop

- Loops will have bugs and will be frustrating!
- In the console, manually set an index: i.e. \texttt{i<-1}
- Then individually run lines *inside* the loop to verify that they work
- More advanced debugging tools for R scripts: https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio

## But wait! Couldn't I do this without a loop in tidyverse?

*Yes! We'll do it later in the lecture*

You usually don't need to use loops with tidyverse coding, but it's still useful to learn.

## Formatting loop output flexibly

- Generally, we have to pre-allocate an object with the correct dimensions for a loop
- e.g. If we want to store 5 rows of 2 columns, we need to make an object with those dimensions before the loop
- However, we can use lists to let R flexibly store loop output

## Using lists for loop output

```{r size = "tiny"}
### create index vector
digits<-seq(from=1,to=5, by=1)
### allocate output vector of needed length
output<-list()
for(i in 1:length(digits)){
  output[[i]]<-digits[i]*2 # store in output at position i
}
str(output)
## make into vector after processing
unlist(output)
### use bind_rows() instead of unlist() 
### if you are storing data frames
```

## Data for today: election results

```{r size = "tiny"}
results<-read_csv("./data/1976-2016-president.csv")
head(results)
results<-results %>% 
  filter(year==2016) %>% 
  filter(candidate=="Clinton, Hillary" | 
           candidate=="Trump, Donald J.") %>% 
  group_by(state_po, candidate) %>% 
  summarise(pct_vote = sum(candidatevotes)/sum(totalvotes) * 100)
```

## Joining data frames

- We can join (or merger) two data frames together by common variables
- Joining variables must have identical column names, types, and values

## Joining election results and election predictions

*How are both datasets structured? What common variables could we join on?*

```{r size = "tiny"}
glimpse(polls)
glimpse(results)
```

## Restructuring data for join

- State abbreviation is a common column for both
- Candidate is a column in results, and is spread over column names in polls
- We want to join, such that the election results for each candidate are joined onto each poll for a state. 
- For example, Nevada poll results for Clinton should match onto Nevada election results
- Note that there is more than one poll available for most states, but only one election result

## Rename columns to match

Rename state in polls to state_po to match across data.frames

```{r}
polls<-polls %>% 
  rename(state_po = state)
names(polls)
```

## Spread candidate across columns in results

- Take the candidate column in results, and make one column for each candidate
- Note that this structure matches the structure of polls

```{r size = "tiny"}
results_wide<-results %>% 
  mutate(candidate = case_when(
    candidate == "Clinton, Hillary" ~ "Clinton",
    candidate == "Trump, Donald J." ~ "Trump"
  )) %>% 
  spread(key = candidate, value = pct_vote) %>% 
  rename(clinton_vote = Clinton, 
         trump_vote = Trump)

head(results_wide)
```

## Join them

- left_join() joins the object on the right to the object on the left, retaining all rows in the left hand object, but potentially removing rows in the right hand object. 

- All columns are preserved.

```{r size = "tiny"}
polls_results<-polls %>% 
  left_join(results_wide)

glimpse(polls_results)
```

## Check data structure to ensure we didn't create duplicates in the final object

```{r}
nrow(polls)
nrow(polls_results)
ncol(polls)
ncol(polls_results)
```

## Calculate prediction error

Error is a general term for how wrong our guess is. We can generally calculate error by subtracting the observation from our prediction. 

prediction error = predicted value - observed value.

```{r}
polls_results<-polls_results %>% 
  mutate(error.clinton = Clinton - clinton_vote,
         error.trump = Trump - trump_vote)

## format error data for plotting / faceting
## turn wide -> long. gather() is the inverse of spread()
plot_errors<-polls_results %>% 
  select(error.clinton, error.trump) %>% 
  gather(key = "candidate", value  = "error") %>% 
  mutate(candidate = case_when(
    candidate == "error.clinton" ~ "Clinton",
    candidate == "error.trump" ~ "Trump"
  ))
```

## Evaluate the errors
```{r size = "tiny", fig.height = 3}
ggplot(plot_errors,
       aes(x = error)) + 
  geom_histogram() + 
  geom_vline(aes(xintercept = 0), lty=2) +
  facet_wrap(~candidate)
```

## Evaluate the errors
```{r}
polls_results %>% 
  summarise(error.clinton.mean = mean(error.clinton),
            error.trump.mean = mean(error.trump))
```

## Root Mean Square Error

RMSE provides a measure of absolute error, where positive and negative errors don't negate each other

$$RMSE = \sqrt{\frac{\sum_{i=1}^n(\hat{y} - y)^2}{n{}}}$$

```{r}
polls_results %>% 
  summarise(rmse.clinton = sqrt(mean(error.clinton^2)),
            rmse.trump = sqrt(mean(error.trump^2)))
```

## Conclusions on errors

1. Polls had similar magnitude of error for both candidates (RMSE)
2. Poll errors were consistently negative for Trump, were zero on average for Clinton. 

## Classification and prediction

How many polls called it right?

1. Make an average prediction for each state across polls
2. Whichever candidate has the highest average polling number is predicted the winner


## Making a prediction based on the polls

```{r size = "scriptsize"}
polls_classify<-polls_results %>% 
  group_by(state_po) %>% 
  summarise(clinton_mn = mean(Clinton),
            trump_mn = mean(Trump)) %>% 
  mutate(clinton_wins_pred = clinton_mn>trump_mn)

table(polls_classify$clinton_wins_pred)
```

## What percent of electoral college votes does our prediction yield for Clinton

```{r}
polls_classify %>% 
  left_join(polls %>% 
              select(state_po, electoral_votes) %>% 
              distinct()) %>% 
  summarise(clinton_ec_votes_share_pred = sum(clinton_wins_pred * electoral_votes)/538)

## actual result
227/538
```

## Classification: potential outcomes for binary predictions

**Bold** cells are correct classifications. 

|                     | Positive, obs. | Negative, obs. |
|---------------------|--------------------|--------------------|
| Positive, pred. | **True positive**      | False positive     |
| Negative, pred. | False negative     | **True negative**      |

## Check our performance

- First, join the election data onto our predictions
- Remove duplicate rows (because many polls are run per state, but only one election!)

```{r}
polls_classify<-polls_classify %>% 
  select(state_po, clinton_wins_pred) %>% 
  left_join(polls_results %>% 
              select(state_po, clinton_vote, trump_vote) %>% 
              distinct()) 
```

## Check our performance

- Then make an election binary outcome

```{r}
polls_classify<-polls_classify%>% 
  mutate(clinton_wins_vote = clinton_vote>trump_vote) %>% 
  select(-clinton_vote, -trump_vote)
```

## How often were the polls right?

```{r}
## calculate proportion of accurate classifications
## i.e. clinton_wins_pred == clinton_wins_vote

polls_classify %>% 
  summarise(mean(clinton_wins_pred == clinton_wins_vote))
```

## Which ones did they get wrong?

```{r}
## Get misclassifications
polls_classify %>% 
  filter(clinton_wins_pred!=clinton_wins_vote)
```

What kind of classification error is this?

## Summary

- Prediction and classification are core practices in statistics
- We can make predictions, then compare them to actual outcomes to evaluate our performance
- The best test of a theory is prediction. Keep predictive validation in mind when designing research and assessing theory.

In lab, we will practice loops, joins, gathers and spreads