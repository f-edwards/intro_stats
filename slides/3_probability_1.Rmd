---
title: "Probability, 1"
author: "Frank Edwards"
output: binb::metropolis
---

```{r setup, include=FALSE}
rm(list=ls())
library(tidyverse)
library(pander)
library(qss)

options(xtable.comment = FALSE)
theme_set(theme_bw())
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
knitr::opts_chunk$set(warning=FALSE, message=FALSE, tidy = F, size = "tiny")
```

## Probability

**How often, on average, does an event occur? **

Probability is a set of tools for describing randomness. 

Probability helps us sort signal (patterns) from noise.

## Two core theories

*Frequentist:* Probability is the proportion of times an event occurs if we repeat an experiment under the same conditions many times

## Consider a simple experiment

What is the probability of obtaining a heads on a single fair coin flip?

```{r size = "tiny"}
flip_n_coins<-function(x){
  flip<-rbinom(x, 1, 0.5)
  flip<-ifelse(flip==1, "Heads", "Tails")
  return(flip)
}
```
\pause

```{r}
flip_n_coins(1)
```
\pause
```{r}
flip_n_coins(1)
```
\pause
```{r}
flip_n_coins(1)
```
\pause

What is $\frac{\sum_1^n x_i}{n}$ where $x_i=1$ when the coin is heads?

## Probability as the average outcome under repeat experiments

```{r}
sum((flip_n_coins(5)=="Heads")/5)
```
\pause
```{r}
sum((flip_n_coins(20)=="Heads")/20)
```
\pause
```{r}
sum((flip_n_coins(50)=="Heads")/50)
```
\pause
```{r}
sum((flip_n_coins(1000)=="Heads")/1000)
```
\pause
```{r}
sum((flip_n_coins(100000)=="Heads")/100000)
```

## Frequentist probability

If $n_x$ is the number of heads, and $n_t$ is the number of coin flips, then the probability of heads is

$$P(x) \approx \frac{n_x}{n_t}$$
$$P(x) = \lim_{n_t\to\infty} \frac{n_x}{n_t}$$

## Bayesian probability

*Bayesian:* Probability is a subjective judgment about the likelihood that an event occurs, with endpoints at 0 (never occurs) and 1 (always occurs). Repeat experiments are often nonsensical.

\pause

I have strong prior information that a fair coin will be heads half of the time, and tails half of the time. If I flip coins and see different patterns, I may change my beliefs about the likelihood of a heads.

## Definitions

*Deterministic* processes do not include randomness. For example, if I drop a ball, it will fall (because gravity). \pause

*Stochastic* events include randomness. For example, if I flip a fair coin, it will be heads half of the time. \pause

Nearly all social processes are have random components, and can be treated as *stochastic*. 

## Definitions and axioms

- Experiment: an action that produces stochastic events \pause
- Sample space ($\Omega$): a set of all possible outcomes of the experiment \pause
- Event: a subset of the sample space

## Example: coin flips

- Experiment
    
    1. flip a coin
    2. roll a dice

\pause

- Sample space $\Omega$

    1. {Heads, Tails}
    2. {1,2,3,4,5,6}

\pause

- Event

    1. Heads, tails, not heads, heads or tails, heads and tails
    2. 3, even number, anything but 6

## Probability with equal likelihood of events

If all outcomes are equally likely, and $n$ represents the number of elements in a given set, then probability $P$ of event $A$ is:

\[P(A) = \frac{n_A}{n_\Omega}\] 

## Probability axioms

1. The probability of any event A is non-negative: $P(A)\geq0$ \pause
2. If an experiment is conducted, the probability that one of the outcomes in the sample space occurs is 1: $P(\Omega)=1$ \pause
3. Addition rule: If events A and B are mutually exclusive: \[P(A \textnormal{ or } B) = P(A) + P(B)\]

## Probability that an event doesn't occur

$$1-P(\textnormal{not } A) = P(A)$$
\pause

If $P(\textnormal{rolling a 6}) = \frac{1}{6}$ then $P(\textnormal{not rolling a 6}) = 1 - \frac{1}{6}=\frac{5}{6}$

## Law of total probability

$$P(A) = P(A \textnormal{ and } B) + P(A \textnormal{ and not } B)$$

\pause

Assume the sample space for A is [eats pizza, does not eat pizza], and the sample space for B is [happy, unhappy]. \pause

If $P(\textnormal{eats pizza}) = 0.5$ and $P(\textnormal{eats pizza, happy}) = 0.4$, then $P(\textnormal{eats pizza, unhappy})  = 0.1$

## General addition rule

$$P(A \textnormal{ or } B) = P(A) + P(B) - P(A \textnormal{ and } B)$$


If $P(\textnormal{happy})=0.5$, then $P(\textnormal{eats pizza or happy})=0.6$

# Three kinds of probability

## Joint probability

The joint probability of two events (A and B) occurring is expressed as

\[P(A \textnormal{ and } B)\]

## Marginal probability

The marginal probability of an event B is 

\[P(B)\]

## Conditional probability

The conditional probability of event $A$ occurring given that event $B$ occurred is the ratio of the joint probability of A and B divided by the marginal probability of B

\[P(A|B) = \frac{P(A \textnormal{ and } B)}{P(B)}\]

# Working with some real data

## Voter files

```{r}
data("FLVoters")
voters<-na.omit(FLVoters)
head(voters)
```

## Marginal probability

What is the probability that a randomly sampled voter in the population is Black: $P(Black) = ?$

```{r}
voters %>% 
  count(race, name = "voters") %>% 
  mutate(p = voters/sum(voters))
```

Is a woman: $P(Woman)= ?$

```{r}
voters %>% 
  count(gender) %>% 
  mutate(n = n/sum(n))
```

## Joint probability

What is the probability that a voter is a Black woman: $P(\textnormal{Black and woman}) = ?$

```{r}
voters %>% 
  count(gender, race) %>% 
  mutate(n = n/sum(n)) %>% 
  pivot_wider(names_from = gender, values_from = n)
```

## What is the probability that a voter is a woman? 

```{r echo = FALSE}
voters %>% 
  count(gender, race) %>% 
  mutate(n = n/sum(n)) %>% 
  pivot_wider(names_from = gender, values_from = n)
```

Use the law of total probability:

\[P(A) = P(A \textnormal{ and } B) + P(A \textnormal{ and not } B)\]

put differently, for all categories of B $i$:

\[P(A) = \sum_{i=1}^n{P(A \textnormal{ and } B_i)}\]

## Conditional probability

If a voter is a man, what is the probability that he is Asian: $P(\textnormal{Asian|man})= ?$

```{r}
voters %>% 
  filter(gender=="m") %>% 
  count(race) %>% 
  mutate(n=n/sum(n))
```

## Conditional probability

Alternatively, we can use the definition of conditional probability as the ratio of the joint probability to the marginal probability: 

\[P(\textnormal{Asian|man}) = \frac{P(\textnormal{Asian and man})}{P(\textnormal{man})}\]

```{r}
voters %>% 
  count(gender, race) %>% 
  mutate(n = n/sum(n))%>% 
  pivot_wider(names_from = gender, values_from = n)
```

## Conditioning on more than one variable

What is the probability that a male voter over age 60 is white?

\[P(\textnormal{white|male and over 60)}\]

```{r}
voters %>% 
  mutate(over60=age>60) %>% 
  count(over60, gender, race) %>% 
  mutate(n=n/sum(n)) %>% 
  pivot_wider(names_from = gender, values_from = n) 

```

```{r}
#P(black and male) = .0566
#P(black) = 0.0744 + 0.0566
#P(male) = 0.0101 + 0.0566 + 0.0577 + 0.00132 + 0.0167 + 0.322
p_b<-0.0744 + 0.0566
p_m<-0.0101 + 0.0566 + 0.0577 + 0.00132 + 0.0167 + 0.322
```


## Conditioning on more than one variable

In general:

\[P(A \textnormal{ and }B|C) = \frac{P(A \textnormal{ and } B \textnormal{ and } C)}{P(C)}\]

and 

\[P(A|B \textnormal{ and }C) = \frac{P(A \textnormal{ and } B \textnormal{ and } C)}{P(B \textnormal{ and } C)}\]

## Independence

Two events are independent if knowledge of one event gives us no information about the other event. 

$P(A|B)=P(A)$ and $P(B|A)=P(B)$

\[ A \perp B \] 

if and only if 

\[P(A \textnormal{ and } B) = P(A)P(B)\]

## Bayes' rule

Recall that a Bayesian perspective treats probability as a subjective opinion about how likely an event is. How should we change our beliefs after we make observations about the world? \pause

Bayes' rule formalizes how we should update our beliefs based on evidence:

\[P(A|B) = \frac{P(B|A)P(A)}{P(B)}\]

\pause

## Prior beliefs and evidence

If we have a *prior* belief that event A has $P(A)$ chance of occurring, then we observe some data, represented as event $B$, we update our beliefs and obtain a *posterior probability* $P(A|B)$. 

\[P(A|B) = \frac{P(B|A)P(A)}{P(B)}\]

## Example: Detecting breast cancer

How good is a mammogram at detecting breast cancer? 

What we know: One percent of women have breast cancer. 80 percent of people who have cancer and take a mammogram test positive. 9.6 percent of people who take a mammogram get a positive result when they do not have breast cancer.  \pause

If you take a mammogram and get a positive result, what is the probability that you have breast cancer?

## Rewriting as probabilities

One percent of women have breast cancer

\[P(\textnormal{Cancer}) = 0.01\] \pause

80 percent of people who have cancer and take a mammogram test positive

\[P(\textnormal{Test positive|Cancer}) = 0.8\] \pause

9.6 percent of people who take a mammogram get a positive result when they do not have breast cancer

\[P(\textnormal{Test positive|No cancer}) = 0.096\]

## Using Bayes' rule

The prior probability of having cancer is 0.01. How should we update our belief that someone has cancer based on a positive test?

\[P(A|B) = \frac{P(B|A)P(A)}{P(B)}\]

Using the law of total probability, we can rewrite the denominator as:

\[P(B) = P(B|A)P(A) + P(B|\textnormal{ not A})P(\textnormal{not }A)\]

## Using Bayes' rule

We can apply Bayes' rule for A = Cancer, B = positive test:

\[P(\textnormal{Cancer|Test positive})=\] 

\[\frac{P(\textnormal{Test positive|Cancer})P(\textnormal{Cancer})} {P(\textnormal{Test positive)}}\]

\[P(\textnormal{Cancer|Test positive})=\frac{0.8 \times 0.01}{0.8 \times 0.01 +  0.096 \times 0.99}\]

```{r}
(0.8 *  0.01)/(0.8 *  0.01 + 0.096 * 0.99)
```

The probability that someone has cancer given a prior probability of one percent and a positive test is about 0.078

