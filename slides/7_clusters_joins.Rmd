---
title: "Measurement and visualization, 2"
author: "Frank Edwards"
date: "10/26/2021"
output: binb::metropolis
---

```{r setup, include=FALSE}
rm(list=ls())
library(tidyverse)
library(MASS)
select<-dplyr::select
set.seed(1)

options(xtable.comment = FALSE)
theme_set(theme_bw())
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
knitr::opts_chunk$set(warning=FALSE, message=FALSE, tidy = F, size = "small")
```

## Correlation

```{r echo = FALSE}
library(MASS)
select<-dplyr::select
cors<-seq(from=0, to =1, by = 0.1)
cor_plot<-list()
for(i in 1:length(cors)){
  cor_plot[[i]] <- mvrnorm(50, 
                      mu = c(0,0), 
                      Sigma = matrix(c(1,cors[i],cors[i],1), ncol = 2),
                      empirical = TRUE)
  cor_plot[[i]]<-as.data.frame(cor_plot[[i]])
  cor_plot[[i]]$cor<-cors[i]
}
cor_plot<-bind_rows(cor_plot)

ggplot(cor_plot, aes(x=V1, y = V2)) + 
  geom_point() +
  facet_wrap(~cor)
```

## Correlation

```{r echo = FALSE}
library(MASS)
select<-dplyr::select
cors<-seq(from=0, to =1, by = 0.1)
cor_plot<-list()
for(i in 1:length(cors)){
  cor_plot[[i]] <- mvrnorm(50, 
                      mu = c(0,0), 
                      Sigma = matrix(c(1,cors[i],cors[i],1), ncol = 2),
                      empirical = TRUE)
  cor_plot[[i]]<-as.data.frame(cor_plot[[i]])
  cor_plot[[i]]$cor<-cors[i]
}
cor_plot<-bind_rows(cor_plot)

ggplot(cor_plot, aes(x=V1, y = V2)) + 
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~cor)
```

## Correlation (math time): Z-scores

First, we need the variables to be comparable, so we transform them to be on a standard deviation scale.

A $z$-score scales a variable measures the number of standard deviations an observation is away from it's mean.

\[z\textrm{ score of }x_i = \frac{x_i-\bar{x}}{S_x} \]

Where $\bar{x}$ is the mean, and $S_x$ is the standard deviation of variable $x$. Z scores have a mean zero, and a range defined by the range of the data on a standard deviation scale. 

For a normally (Gaussian) distributed variable, this will typically range between $[-3,3]$ 

In R, we can transform a numeric into a $z$-score using \texttt{scale()}

## Z-scores in R

```{r}
ipv<-read.csv("https://raw.githubusercontent.com/f-edwards/intro_stats/master/data/dhs_ipv.csv")

ipv_scale<-ipv %>% 
  mutate(sec_scale = scale(sec_school)) %>% 
  select(sec_school, sec_scale) 
summary(ipv_scale)
```

## Z-scores in R

```{r size = "tiny"}
ggplot(ipv_scale, aes(x=sec_school, y=sec_scale)) + geom_point()
```

## Correlation

Correlation measures the degree to which two variables are associated with each other. We often use the letter $r$ to denote a correlation.

\[r(x,y) = \frac{1}{n}\sum_{i=1}^{n} \frac{x_i-\bar{x}}{S_x} \times \frac{y_i-\bar{y}}{S_y}\]

Note that this is equal to the average of the product of the $z-scores$ of $x$ and $y$

In R, you can use \texttt{cor()}

## Returning to our example: Are sec_school and no_media correlated?

```{r echo = FALSE}
ggplot(ipv, aes(x = sec_school, y =no_media, color = region)) + geom_point()
```

## Obtaining the correlation coefficient

```{r}
cor(ipv$sec_school, ipv$no_media, use="complete")
## z score method
mean(scale(ipv$sec_school) * scale(ipv$no_media), na.rm=TRUE)
```

# Clustering

## Latent structure

Data often *cluster* based on unobserved or unobservable characteristics. We can use *classification methods* to try to uncover these latent structures in data. 

$k$-means is a straightforward method we can use to identify $k$ latent groupings in our data, based on proximity of observations for specified variables.

## The k-means algorithm

An algorithm is a sequential set of steps used to solve a problem.

A *centroid* is the mean value of a cluster within a group.

1. Choose the initial centroids for each of the $k$ clusters
2. Assign each observation to the cluster with the nearest centroid
3. Assign a new centroid based on the within-cluster mean for assigned observations
4. Repeat steps 2 and 3 until the cluster assignments no longer change

We arbitrarily choose the number of clusters $k$, and R randomly selects starting centroid values for step 1.

## The k-means algorithm

![](./vis/kmeans.jpg)

## Implementing k-means for the IPV data

```{r size = "tiny"}
ipv_scale<-ipv %>%
  select(sec_school, no_media) %>%
  mutate(sec_school = scale(sec_school),
         no_media = scale(no_media)) %>%
  filter(!(is.na(sec_school)), !(is.na(no_media))) 

ipv_kmeans<-kmeans(ipv_scale,
                   centers = 3, 
                   nstart=10)
```

## Working with the k-means object

```{r size = "tiny"}
ipv_kmeans
```

## Pull out what we need from the list

```{r}
ipv_clusters<-ipv %>%
  filter(!(is.na(sec_school)), !(is.na(no_media))) %>%
  mutate(cluster = factor(ipv_kmeans$cluster))

centers<-data.frame(ipv_kmeans$centers)

centers
```

## Plot it!

```{r size = "tiny", fig.height = 3}
ggplot(ipv_clusters, aes(x = scale(sec_school),
                         y =scale(no_media),
                         color = cluster)) +
  geom_point() +
  geom_point(data = centers, 
             aes(x=sec_school, 
                 y=no_media),
             color = "black", size = 4, shape = 3)

```

## What if we thought there were 4 clusters?

```{r echo = FALSE, fig.height = 3}
ipv_kmeans<-ipv %>%
  select(sec_school, no_media) %>%
  mutate(sec_school = scale(sec_school),
         no_media = scale(no_media)) %>%
  filter(!(is.na(sec_school)), !(is.na(no_media))) %>%
  kmeans(centers = 4, nstart=10)

ipv_clusters<-ipv %>%
  filter(!(is.na(sec_school)), !(is.na(no_media))) %>%
  mutate(cluster = factor(ipv_kmeans$cluster))

centers<-data.frame(ipv_kmeans$centers)

ggplot(ipv_clusters, aes(x = scale(sec_school),
                         y =scale(no_media),
                         color = cluster)) +
  geom_point() +
  geom_point(data = centers, aes(x=sec_school, y=no_media),
             color = "black", size = 4, shape = 3)
```

## What if we thought there were 10 clusters?

```{r echo = FALSE, fig.height = 3}
ipv_kmeans<-ipv %>%
  select(sec_school, no_media) %>%
  mutate(sec_school = scale(sec_school),
         no_media = scale(no_media)) %>%
  filter(!(is.na(sec_school)), !(is.na(no_media))) %>%
  kmeans(centers = 10, nstart=10)

ipv_clusters<-ipv %>%
  filter(!(is.na(sec_school)), !(is.na(no_media))) %>%
  mutate(cluster = factor(ipv_kmeans$cluster))

centers<-data.frame(ipv_kmeans$centers)

ggplot(ipv_clusters, aes(x = scale(sec_school),
                         y =scale(no_media),
                         color = cluster)) +
  geom_point() +
  geom_point(data = centers, aes(x=sec_school, y=no_media),
             color = "black", size = 4, shape = 3)
```

## Summary

- Measurement and design matter!
- Always check your data, and think about how unit and item non-response may inform your conclusions
- Think about desirability and other forms of response bias as you interpret your results
- Design visuals and exploratory analyses to check hypotheses about what's going on in the data
- Think about the structure of your data, use descriptive statistics like correlations to describe relationships
- Think about latent structures in your data to capture clustering

# Joining data

## Data for today: polling and the 2016 election

```{r size = "tiny"}
polls<-read.csv("https://raw.githubusercontent.com/f-edwards/intro_stats/master/data/polls2016.csv")
## if not in the .RMD slide file
head(polls)
polls<-polls %>% 
  filter(population=="Likely Voters") %>% 
  select(state, Clinton, Trump, electoral_votes)
```

## Data for today: election results

```{r size = "tiny"}
results<-read.csv("https://raw.githubusercontent.com/f-edwards/intro_stats/master/data/1976-2016-president.csv")
head(results)
results<-results %>% 
  filter(year==2016) %>% 
  filter(candidate=="Clinton, Hillary" | 
           candidate=="Trump, Donald J.") %>% 
  group_by(state_po, candidate) %>% 
  summarise(pct_vote = sum(candidatevotes)/sum(totalvotes) * 100)
```

## Joining data frames

- We can join (or merge) two data frames together by common variables \pause
- Joining variables must have identical column names, types, and values

## Joining election results and election predictions

*How are both datasets structured? What common variables could we join on?*

```{r size = "tiny"}
head(polls)
head(results)
```

## Restructuring data for join

- State abbreviation is a common column for both \pause
- Candidate is a column in results, and is spread over column names in polls \pause
- We want to join, such that the election results for each candidate are joined onto each poll for a state.  \pause
- For example, Nevada poll results for Clinton should match onto Nevada election results \pause
- Note that there is more than one poll available for most states, but only one election result

## Rename columns to match

Rename state in polls to state_po to match across data.frames

```{r size = "tiny"}
polls<-polls %>% 
  rename(state_po = state)
names(polls)
```

## A note on tidy data

- Each column should be a variable \pause
- Values should not be stored in columns \pause

```{r}
head(polls)
```

## Pivot polls from wide format to long format

- Take the candidate name from the column, add a new column for candidate \pause
- Note that this structure matches the structure of results


## pivot_longer

`pivot_longer` reshapes wide data into long data. `pivot_wider` reshapes long data into wide data.

```{r size = "tiny"}
polls_long <- polls %>% 
  pivot_longer(cols = Clinton:Trump,
               names_to = "candidate",
               values_to = "poll_result")

head(polls_long)
```

## Any other problems prior to joining?

```{r size = "tiny"}
head(polls_long)
head(results)
```

## Renaming with a conditional


```{r}
results_new <- results %>% 
  mutate(candidate = case_when(
    candidate == "Clinton, Hillary" ~ "Clinton",
    candidate == "Trump, Donald J." ~ "Trump"
  ))
```

## Renaming using string manipulation

```{r}
results_new2 <- results %>% 
  mutate(candidate = 
           word(candidate, 1))

head(results_new2)

## almost...
```

## Renaming using string manipulation

```{r}
results_new2 <- results_new2 %>% 
  mutate(candidate = 
           str_replace(candidate, ",", ""))

head(results_new2)
```

## Putting it all together

```{r}
results_new2 <- results %>% 
  mutate(candidate = 
           str_replace(
             word(candidate, 1),
             ",", ""))

head(results_new2)
```

# Joins

## Join them

- left_join() joins the object on the right to the object on the left, retaining all rows in the left hand object, but potentially removing rows in the right hand object. \pause

- All columns are preserved.

```{r size = "tiny"}
polls_results<- polls_long %>% 
  left_join(results_new2)

head(polls_results)
```

## Check data structure to ensure we didn't create duplicates in the final object

We want to see the same number of rows in `polls_long` and `polls_results`

```{r}
dim(polls_long)
dim(polls_results)
```
